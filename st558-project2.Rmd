---
title: "Analysis of an Online News Popularity Data Set"
author: "Claudia Donahue and Dane Korver"
date: '2022-06-28'
output: 
  github_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction  

You should have an introduction section that briefly describes the data and the variables you have to work with (just discuss the ones you want to use). Your target variables is the shares variable.

You should also mention the purpose of your analysis and the methods you’ll use to model the response.

You’ll describe those in more detail later.
**This section should be done by the ‘second’ group member.**

The [dataset](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity) we are using summarizes a heterogeneous set of statistics about articles published by Mashable over a period of two years. The goal is to predict the number of shares in social networks (popularity).  

## Data  

Use a relative path to import the data. Subset the data to work on the data channel of interest.
**This section should be done by whoever can get to it first.**  

We'll begin by reading in the data set.  

```{r Read in data using a relative path}
data <- readr::read_csv(file = "OnlineNewsPopularity.csv",
                        show_col_types = FALSE
                        )

head(data)
```

The data has just one column that is not numeric, and that column is the first one and contains URLs for the Mashable articles for each observation. The second column, `timedelta`, is not useful for prediction either. The other columns contain numeric data that we may be able to use to predict the number of shares. The last column is our target variable, `shares`. The data is set up nicely for what we want to do.  

Next we will begin our look at one specific channel by subsetting the data.  

```{r Subset channel of interest}
channel <- "lifestyle" # starting with lifestyle for now

channel <- paste("data_channel_is_", channel, sep = "")

cData <- data[data[channel] == 1, ] # Extract rows of interest

# I kind of want to drop the timedelta column, as well as the 
# unused data_channel_is columns
```

We then split the data into training and testing sets (70% and 30%, respectively). We will only explore the training set, and will keep the testing set in reserve to determine the quality of our predictions. We will use the function `createDataPartition()` from the `caret` package to split the data. 

```{r Split data into training and testing, message=FALSE}
library(caret) # Using createDataPartition from caret

set.seed(33) # for reproducibility 

# Index to split on
idx <- createDataPartition(y = data$shares, p = 0.7, list = FALSE)

# Subset
training <- cData[idx, ]
testing <- cData[-idx, ]

```


## Summarizations  

**Each group member is responsible for producing some summary statistics (means, sds, contingency tables, etc.) and for producing at least three graphs (each) of the data.**  

Then we thought about the characteristics of an online article that might be associated with someone deciding to "share" the article to someone else. 

We thought it was probably important to consider both the timing of the article, the headline, and the article's content. By timing, we mean that perhaps some readers are more likely to click on an article and share it on the weekend because they generally have more free time to read. We looked at numbers of shares on weekends vs. weekdays to see if that held true.   

```{r summary by day of week, message=FALSE}
library(tidyverse)

training %>% group_by(is_weekend) %>%
  summarise(avgShares = mean(shares),
            medianShares = median(shares),
            stdevShares = sd(shares)
            )
```
The average and median calculations are measures of centrality, so that we can compare shares on weekends vs. on weekdays. The standard deviation of shares is a measure of the spread of the data, so that we can see if the average number of shares per article is more consistent on weekends or on weekdays. A higher standard deviation means the number of shares varies more from the average. 

Then we wanted to create a visualization that would show us how the variable `title_sentiment_polarity` seemed to impact the number of shares. Our thought was that maybe an article with a more polarizing title would get more shares than one less polarizing, as people want to have some justification for urging a friend to spend time reading the article. A polarizing sentiment could provide that justification for some people. We will plot the polarity of the title's sentiment and include information on the number of words in the title.    

```{r Scatter Plot title impact on shares, warning=FALSE}
ggplot(training, aes(x = title_sentiment_polarity,
                     y = shares,
                     color = n_tokens_title)) +
  geom_point() +
  labs(title = "Title Sentiment vs Number of Shares",
       x = "Sentiment Polarity of Title",
       y = "Number of Shares",
       color = "# Words in Title")
```

Then we wanted to look at the outliers--the top articles by shares, so we grabbed a list of those URLs, along with the number of shares. 

```{r Top articles}
head(training[order(training$shares, decreasing = TRUE), c("url", "shares")], 10)
```

Finally, we thought about how the content of an article might lead someone to share it. Maybe people share shorter articles more than long ones. Maybe people like to share links with images more than links without images, we thought. So we took a look at an article's length and number of images vs. number of shares.  


```{r Scatter plot of Article content length and images, warning=FALSE}
ggplot(training, aes(x = n_tokens_content,
                     y = shares,
                     color = num_imgs)) +
  geom_point() +
  labs(title = "Article Length vs Number of Shares",
       x = "Number of Words in Article",
       y = "Number of Shares",
       color = "# Images")

```

Within its metadata, a website can be assigned a number of keywords, which used to give search engines more information about the content. We wondered how the number of keywords related to the number of shares, given that this data is several years old, and that used to be considered a part of search engine optimization.  

```{r Histogram of Keywords vs shares}
ggplot(training, aes(x = num_keywords,
                     y = shares)) +
  geom_count() +
  labs(title = "Number of Keywords vs. Shares",
       x = "Number of Keywords",
       y = "Number of Shares")
```

Before the modeling step, we took one final look at some of the other variables we thought might be important in predicting number of shares, based on the summaries above and our own experiences. 

```{r exploratory graph}
library(GGally)
training %>% 
  select(self_reference_avg_sharess, LDA_00, rate_negative_words, shares) %>%
  GGally::ggpairs()
```

Looking across the bottom row of graphs, we can see whether any relationships between `shares` and another variable are evident. 

## Modeling  

The goal is to create models for predicting the number of shares in some way. Each group member should contribute a linear regression model and an ensemble tree-based model. As we are automating things, describing the chosen model is tough, so no need to worry about that.  

**The first group member should fit a random forest model and the second group member should fit a boosted tree model.** Both models should be chosen using cross-validation.  

Prior to the models fit using linear regression, **the first group member should provide a short but thorough explanation of the idea of a linear regression model.**  

### Linear Regression  
Linear regression is a way of calculating the relationship between one or more input/independent variables and an output/dependent variable. (More than one input variable would make the model a multiple regression) In this case, our output variables is `shares`, the number of times a Mashable article was shared. A linear regression assumes that one or more other variables are correlated with the number of shares, and that the relationship can be visually represented as a straight line. The mathematical equation for a basic linear regression is: 

$y = B*x+A$

where y is the dependent variable, x is an independent variable, and A and B are coefficients for the line's y-intercept and slope. The values for these coefficients are chosen to minimize the error between the model's predictions and the actual outcomes in the training data. 

With that, here we go! We are using the `train()` function from the `caret` package to make the model. We will use the results of 5-fold cross-validation to evaluate the performance of all our models and, later, to compare them.

This first multiple regression will try to predict the number of shares based on the number of keywords, the number of words in the article, and the average word length.  

```{r Linear regression}
# building the model
fit1 <- train(shares ~ num_keywords + n_tokens_content + average_token_length, 
              data = training, 
              method = "lm", # linear regression
              na.action = na.omit,
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", number = 5)
              )
# look at the resulting coefficients
fit1$finalModel
fit1
```


Prior to each ensemble model, you should provide a short but reasonably thorough explanation of the ensemble model you are using (so **one for each group member**).  

```{r Random Forest model, message = FALSE}
# load required package
library(randomForest)
# set up the mtry parameter 
tunegrid <- expand.grid(.mtry=c(1:15))

#trainingRF <- na.omit(training)
#train model
rfFit <- train(x = trainingRF[,3:60], 
                y = trainingRF$shares,
                method = "rf",
               na.action = na.omit,
                tuneGrid = tunegrid,
                preProcess = c("center", "scale"),
                trControl = trainControl(method = "repeatedcv", 
                                         number = 5, repeats = 3),
                )
rfFit

# use the tree to make predictions based on testing data
pred <- predict(rfFit, newdata = testing)
# Make a confusion matrix
confusionMatrix(pred, testing$shares)
```



## Comparison  

All four of the models should be compared on the test set and a winner declared (this should be automated to be correct across all the created documents).  

**This can be done by one group member and the automation done by the other.**  


## Automation  

Once you’ve completed the above for a particular data channel, adapt the code so that you can use a parameter in your build process. You should be able to automatically generate an analysis report for each data_channel_is_* variable - although again, you may want to create a new variable to help with the
subsetting. You’ll end up with six total outputted documents.  

**This should be done by the group member that doesn’t automate the comparison of models part.**  






